---
uid: 2025081220015022
title: 'Obsidian 插件：Mini-RAG'
tags: ['自动化与AI', '第三方工具集成', '效率工具', '学习与教育', '白板学术与科研', 'obsidian插件']
description: '用本地运行的大语言模型（LLM）或人工智能，为你的笔记运用检索增强生成（RAG）技术。'
author: AI
type: auto
draft: false
editable: false
modified: 20240101000000
---

# Obsidian 插件：Mini-RAG

> [!Note] 插件名片
> - 插件名称：Mini-RAG
> - 插件作者：John Wheatley
> - 插件说明：用本地运行的大语言模型（LLM）或人工智能，为你的笔记运用检索增强生成（RAG）技术。
> - 插件分类：['自动化与AI', '第三方工具集成', '效率工具', '学习与教育', '白板学术与科研', 'obsidian插件']
> - 项目地址：[点我访问](https://github.com/jjwheatley/mini-rag)
> - 国内下载地址：[下载安装](https://pkmer.cn/products/plugin/pluginMarket/?mini-rag)
> - 自述文件：[Readme](https://ghproxy.net/https://raw.githubusercontent.com/jjwheatley/mini-rag/master/README.md)



## 概述

### Mini - RAG插件总结
1. **主要功能**：借助本地运行的大语言模型（LLM），实现基于所选Obsidian笔记和文件夹的检索增强生成（RAG），让用户能与之聊天，并可保存对话。
2. **适用场景**：适用于需要在Obsidian笔记内容语境下与本地大语言模型交互的场景，如知识整理、信息查询等。
3. **核心特色**：依赖本地运行的Ollama提供响应，支持选择本地安装的Ollama模型，可设置温度以调整回复的创造性，还能开启无上下文聊天。
4. **使用建议**：使用前需安装Ollama，可从[官网](https://ollama.com/download)下载。在Obsidian的社区插件选项中配置Ollama URL、模型、温度等参数。通过右键菜单开启聊天，聊天过程中若要保存对话，点击“保存”按钮，后续继续对话后若要更新保存内容，需再次点击“保存”。


> [!help] 
> 这篇插件文章还没有人贡献，欢迎占坑！
> 如果您有好的想法欢迎提交PR或者文末留言。
> 

---


